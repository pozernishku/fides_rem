{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import warcat.model\n",
    "# from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "import re\n",
    "regex_html_char_num = re.compile(r\"&#?[0-9a-zA-Z]*;\", re.MULTILINE)\n",
    "html_amp_dash_dict = {'&amp;':'&','&ndash;':'–','&mdash;':'—','&horbar;':'―','&minus;':'−',\n",
    "                     '&hyphen;':'‐','&dash;':'‐','&HorizontalLine;':'─','&hybull;':'⁃',\n",
    "                     '&#45;':'-','&#x2D;':'-','&#X2D;':'-','&#x2d;':'-','&#X2d;':'-',\n",
    "                     '&#8211;':'–','&#x2013;':'–','&#X2013;':'–','&#8212;':'—','&#x2014;':'—',\n",
    "                     '&#X2014;':'—','&#8722;':'−','&#x2212':'−','&#X2212':'−'}\n",
    "\n",
    "regex_non_relevant_symb = re.compile(r\"(?<=(\\w))[^\\s\\w]+(?=(\\w))\", re.MULTILINE)\n",
    "regex_alone_digits = re.compile(r\"((^\\d+(?=\\s))|((?<=\\s)[\\d]+(?=\\s))|((?<=\\s)\\d+$))\", re.MULTILINE)\n",
    "regex_dot_capital = re.compile(r\"[.](\\w)\", re.MULTILINE)\n",
    "regex_white_space = re.compile(r\"\\s+\", re.MULTILINE)\n",
    "dashes_set = {'–','—','―','−','‐','─','⁃','-'}\n",
    "period = '.'\n",
    "apostrophe_set = {\"'\",'‵',\"’\",'‘','´','`','′'}\n",
    "digits_set = {'0','1','2','3','4','5','6','7','8','9'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def html_repl_func(match):\n",
    "    if match.group() in html_amp_dash_dict:\n",
    "        return html_amp_dash_dict[match.group()]\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "-удалить все хтмл-символы, кроме дефиса и амперсанда (их заменять на символ);\n",
    "'''\n",
    "def clean_html_char_num(text):\n",
    "    match = regex_html_char_num.search(text)\n",
    "    if match:\n",
    "        return regex_html_char_num.sub(html_repl_func, text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def non_relevant_repl_func(match):\n",
    "    if len(match.group(0)) > 1:\n",
    "        return ' '\n",
    "    elif ((match.group(0) in dashes_set or match.group(0) in apostrophe_set or match.group(0) == period) \n",
    "          and (match.group(1).isalpha() and match.group(2).isalpha())):\n",
    "        return match.group(0)\n",
    "    elif ((match.group(0) in dashes_set)\n",
    "          and ( (match.group(1).isalpha() and match.group(2) in digits_set)\n",
    "             or (match.group(2).isalpha() and match.group(1) in digits_set))):\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        if match.group(1).isalpha() and match.group(2).isalpha():\n",
    "            return ' '\n",
    "        elif ((match.group(1).isalpha() and match.group(2) in digits_set) \n",
    "             or (match.group(2).isalpha() and match.group(1) in digits_set)):\n",
    "            return ' '\n",
    "        else:\n",
    "            return match.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_capital_repl_func(match):\n",
    "    if match.group(1).isupper():\n",
    "        return '. ' + match.group(1)\n",
    "    else:\n",
    "        return match.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "-все небуквенные и нецифровые символы между буквами заменяются на пробелы за исключением:\n",
    "тире (все виды), точки и апострофа (их тоже несколько) между буквами не обрабатываются;\n",
    "тире (все виды) между сочетаниями буква-цифра (и наоборот) не обрабатываются;\n",
    "'''\n",
    "def clean_non_relevant_symb(text):\n",
    "    match = regex_non_relevant_symb.search(text)\n",
    "    if match:\n",
    "        return regex_non_relevant_symb.sub(non_relevant_repl_func, text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "цифровые последовательности, не содержащие букв, удалятся;\n",
    "# цифры в перемешку с небуквенными символами остаются: A-077-B\n",
    "'''\n",
    "def clean_alone_digits(text):\n",
    "    match = regex_alone_digits.search(text)\n",
    "    if match:\n",
    "        return regex_alone_digits.sub('', text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "сочетание \"точка+одиночная заглавная буква\" разделяются пробелом;\n",
    "'''\n",
    "def separate_dot_capital(text):\n",
    "    match = regex_dot_capital.search(text)\n",
    "    if match:\n",
    "        return regex_dot_capital.sub(dot_capital_repl_func, text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Clean text according to http://redmine-ots.co.spb.ru/issues/7415\n",
    "'''\n",
    "def clean_text(text):\n",
    "    return regex_white_space.sub(' ', separate_dot_capital(\n",
    "        clean_alone_digits(\n",
    "            clean_non_relevant_symb(\n",
    "                clean_html_char_num(text)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "wet_list also accepts compressed files *.warc.wet.gz\n",
    "'''\n",
    "def clean_and_tokenize_wet_files(wet_list=None):\n",
    "    if not wet_list:\n",
    "        print('wet_list is not specified')\n",
    "        return \n",
    "    \n",
    "    wet_list = wet_list[-1:] # one (last 00639) in list (require all list)\n",
    "    \n",
    "    for wet_file in wet_list:\n",
    "        warc = warcat.model.WARC()\n",
    "        warc.load(wet_file)\n",
    "        \n",
    "        pth = os.path.join('./output', wet_file[3:])\n",
    "        os.makedirs(pth, exist_ok=True)\n",
    "        print('File: ', wet_file, 'Records: ', len(warc.records), sep='\\t', end='\\n\\n') # to logs is better\n",
    "        \n",
    "        for i, record in enumerate(warc.records[0:30]): # sliced here!\n",
    "            print('WARC-Type: ', record.warc_type, 'Content-Length: ', record.content_length, \n",
    "                  'Content-Type: ', record.header.fields['content-type'], \n",
    "                  'WARC-Target-URI: ' , record.header.fields.get('WARC-Target-URI'), \n",
    "                  'WARC-Date: ' , record.header.fields.get('WARC-Date'), \n",
    "                  'Num: ', i, sep='\\t') \n",
    "            \n",
    "            if record.warc_type != 'warcinfo':\n",
    "                with record.content_block.get_file() as f:\n",
    "                    text = bytes.decode(f.read())\n",
    "                    file_name_urn = record.header.fields.get('WARC-Record-ID').split(':')[-1][:-1] + '.txt'\n",
    "                    \n",
    "                    with open(os.path.join(pth, file_name_urn), 'w') as f_to_fs:\n",
    "                        f_to_fs.write(clean_text(text))\n",
    "                        \n",
    "#                     print('\\nDirty: \\n\\n', text, end='\\n\\n')\n",
    "#                     print('\\nClean: \\n\\n', clean_text(text), end='\\n\\n')\n",
    "#                     tokenized_text = word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    clean_and_tokenize_wet_files(glob.glob(\"../*.warc.wet*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scr]",
   "language": "python",
   "name": "conda-env-scr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
