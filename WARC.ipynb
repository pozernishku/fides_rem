{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "import warcat.model\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "from operator import itemgetter, attrgetter\n",
    "\n",
    "regex_html_char_num = re.compile(r\"&#?[0-9a-zA-Z]*;\", re.MULTILINE)\n",
    "html_amp_dash_dict = {'&amp;':'&','&ndash;':'–','&mdash;':'—','&horbar;':'―','&minus;':'−',\n",
    "                     '&hyphen;':'‐','&dash;':'‐','&HorizontalLine;':'─','&hybull;':'⁃',\n",
    "                     '&#45;':'-','&#x2D;':'-','&#X2D;':'-','&#x2d;':'-','&#X2d;':'-',\n",
    "                     '&#8211;':'–','&#x2013;':'–','&#X2013;':'–','&#8212;':'—','&#x2014;':'—',\n",
    "                     '&#X2014;':'—','&#8722;':'−','&#x2212':'−','&#X2212':'−'}\n",
    "\n",
    "regex_non_relevant_symb = re.compile(r\"(?<=(\\w))[^\\s\\w]+(?=(\\w))\", re.MULTILINE)\n",
    "regex_remaining_non_relevant_symb = re.compile(r\"[^\\s\\w]+\", re.MULTILINE)\n",
    "regex_alone_digits = re.compile(r\"(?<=\\s)[\\d]+(?=\\s)\", re.MULTILINE)\n",
    "regex_dot_capital = re.compile(r\"[.](\\w)\", re.MULTILINE)\n",
    "regex_white_space = re.compile(r\"\\s+\", re.MULTILINE)\n",
    "\n",
    "regex_email = re.compile(r\"\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,}\\b\", re.MULTILINE | re.IGNORECASE)\n",
    "regex_hashtag = re.compile(r\"(?<!&)#\\w+\\b(?!;)\")\n",
    "regex_www = re.compile(r\"\\b(?:https?://|www\\.)+\\S{3,}\", re.MULTILINE | re.IGNORECASE)\n",
    "\n",
    "dashes_set = {'–','—','―','−','‐','─','⁃','-'}\n",
    "period = '.'\n",
    "ampersand = '&'\n",
    "apostrophe_set = {\"'\",'‵',\"’\",'‘','´','`','′'}\n",
    "digits_set = {'0','1','2','3','4','5','6','7','8','9'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "пожалуй, еще нужно добавить фильтр на длину слова. Скажем, слова, более 30 символов - не обрабатывать.\n",
    "- точки между буквами не обрабатываются за искл. сочетание \"точка+одиночная заглавная буква\" разделяются пробелом;\n",
    "'''\n",
    "def remove_long_words(text, word_length=30):\n",
    "    if text is None:\n",
    "        return ''\n",
    "    \n",
    "    a = 0\n",
    "    s = ''\n",
    "    \n",
    "    for i, c in enumerate(text):\n",
    "        if c == ' ':\n",
    "            if i - a <= word_length:\n",
    "                s += final_cuts(text[a:i+1])\n",
    "                a = i+1\n",
    "            else:\n",
    "                z = final_cuts(text[a:i+1]).strip()\n",
    "                if len(z) <= word_length:\n",
    "                    s += z + ' '\n",
    "                a = i+1\n",
    "    else:\n",
    "        if c == ' ':\n",
    "            return s\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if i - a <= word_length:\n",
    "            s += final_cuts(text[a:i+1])\n",
    "        else:\n",
    "            z = final_cuts(text[a:i+1]).strip()\n",
    "            if len(z) <= word_length:\n",
    "                s += z\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "- отдельно стоящие небуквенные и нецифровые последовательности удалять; это касается и тире, апострофа и амперсанда:\n",
    "Ano Novo – & Australia Day – Good Friday – Easter Saturday - Easter Monday\n",
    "g = 'страница от 10.01.2018. Оригинал '\n",
    "'''\n",
    "def final_cuts(word):\n",
    "    n = len(word)\n",
    "    \n",
    "    if n == 0:\n",
    "        return word\n",
    "    elif n == 1:\n",
    "        if (word in dashes_set or word == period or word == ampersand \n",
    "            or word in apostrophe_set or word == ' ' or word in digits_set):\n",
    "            return ' '\n",
    "        else:\n",
    "            return word\n",
    "    elif n >= 2:\n",
    "        front = word[0]\n",
    "        tail = word[-1]\n",
    "        pre_tail = word[-2:-1]\n",
    "        pre_check_digit = word[-3:-2]\n",
    "        \n",
    "        if (front in dashes_set or front == period or front == ampersand \n",
    "            or front in apostrophe_set):\n",
    "            word = ' ' + word[1:]\n",
    "        \n",
    "        if (tail in dashes_set or tail == period or tail == ampersand \n",
    "            or tail in apostrophe_set):\n",
    "            word = word[:-1] + ' '\n",
    "            \n",
    "        if ((pre_tail in dashes_set or pre_tail == period or pre_tail == ampersand \n",
    "            or pre_tail in apostrophe_set) and tail == ' '):\n",
    "            word = word[:-2] + ' ' + word[-1:]\n",
    "            \n",
    "        if (pre_check_digit in digits_set or pre_tail in digits_set or tail in digits_set or front in digits_set):\n",
    "            word = clean_alone_digits(' ' + word + ' ')\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def html_repl_func(match):\n",
    "    if match.group() in html_amp_dash_dict:\n",
    "        return html_amp_dash_dict[match.group()]\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "-удалить все хтмл-символы, кроме дефиса и амперсанда (их заменять на символ);\n",
    "'''\n",
    "def clean_html_char_num(text):\n",
    "    match = regex_html_char_num.search(text)\n",
    "    if match:\n",
    "        return regex_html_char_num.sub(html_repl_func, text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def non_relevant_repl_func(match):\n",
    "    if len(match.group(0)) > 1:\n",
    "        return ' '\n",
    "    elif ((match.group(0) in dashes_set \n",
    "           or match.group(0) in apostrophe_set \n",
    "           or match.group(0) == period \n",
    "           or match.group(0) == ampersand)\n",
    "          and (match.group(1).isalpha() and match.group(2).isalpha())):\n",
    "        return match.group(0)\n",
    "    elif ((match.group(0) in dashes_set)\n",
    "          and ( (match.group(1).isalpha() and match.group(2) in digits_set)\n",
    "             or (match.group(2).isalpha() and match.group(1) in digits_set))):\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        if match.group(1).isalpha() and match.group(2).isalpha():\n",
    "            return ' '\n",
    "        elif ((match.group(1).isalpha() and match.group(2) in digits_set) \n",
    "             or (match.group(2).isalpha() and match.group(1) in digits_set)\n",
    "             or (match.group(1) in digits_set and match.group(2) in digits_set)):\n",
    "            return ' '\n",
    "        else:\n",
    "            return match.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dot_capital_repl_func(match):\n",
    "    if match.group(1).isupper():\n",
    "        return ' ' + match.group(1)\n",
    "    else:\n",
    "        return match.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "-все небуквенные и нецифровые символы между буквами заменяются на пробелы за исключением:\n",
    "тире (все виды), точки и апострофа (их тоже несколько) между буквами не обрабатываются;\n",
    "тире (все виды) между сочетаниями буква-цифра (и наоборот) не обрабатываются;\n",
    "'''\n",
    "def clean_non_relevant_symb(text):\n",
    "    match = regex_non_relevant_symb.search(text)\n",
    "    if match:\n",
    "        return regex_non_relevant_symb.sub(non_relevant_repl_func, text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "цифровые последовательности, не содержащие букв, удалятся;\n",
    "# цифры в перемешку с небуквенными символами остаются: A-077-B\n",
    "'''\n",
    "def clean_alone_digits(text):\n",
    "    match = regex_alone_digits.search(text)\n",
    "    if match:\n",
    "        return regex_alone_digits.sub('', text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "сочетание \"точка+одиночная заглавная буква\" разделяются пробелом;\n",
    "name: DUC. Enjoy - все точки также удаляются, после обаботки: сочетание \"точка+одиночная заглавная буква\" разделяются пробелом;\n",
    "(Тут заменяются на пробел только те точки, которые стоят перед заглавной буквой)\n",
    "'''\n",
    "def separate_dot_capital(text):\n",
    "    match = regex_dot_capital.search(text)\n",
    "    if match:\n",
    "        return regex_dot_capital.sub(dot_capital_repl_func, text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "name: DUC. Enjoy - все точки также удаляются, после обаботки: сочетание \"точка+одиночная заглавная буква\" разделяются пробелом; \n",
    "удалено условие: тут удаляются все точки [^\\s\\w]+\n",
    "'''\n",
    "def remaining_non_relevant_repl_func(match):\n",
    "    if len(match.group(0)) > 1:\n",
    "        return ' '\n",
    "    elif (match.group(0) == ampersand \n",
    "          or match.group(0) in dashes_set \n",
    "          or match.group(0) == period \n",
    "          or match.group(0) in apostrophe_set):\n",
    "        \n",
    "        if match.start() == 0 or match.start() == match.endpos-1:\n",
    "            return ' '\n",
    "        \n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# НЕ из перечисленных: амперсанд (&), тире(все виды), точка (.), апостраф(все виды)\n",
    "'''\n",
    "идея же в том, чтобы избавиться от небуквенных последовательностей, а также \"помочь\" токенизации при построении частотного распределения. \n",
    "\n",
    "например, \n",
    "stuff, here - тут запятой не должно быть;\n",
    "Flights: FLAGRANTS - здесь не нужно двоеточие;\n",
    "Germany-c60-199?) - здесь скобки и вопр. знака;\n",
    "'''\n",
    "def clean_remaining_non_relevant_symb(text):\n",
    "    match = regex_remaining_non_relevant_symb.search(text)\n",
    "    if match:\n",
    "        return regex_remaining_non_relevant_symb.sub(remaining_non_relevant_repl_func, text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "кстати, выделенные url, e-mail, hash-tag могут также пригодиться для оценки, \n",
    "поэтому есть смысл их не просто удалять, а и по ним строить частотное распределение \n",
    "(например, их кол-во и распределение могут показывать \"связность\" ресурса).\n",
    "'''\n",
    "def clean_from_emails(text):\n",
    "    match = regex_email.search(text)\n",
    "    if match:\n",
    "        return regex_email.sub(' ', text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_from_www(text):\n",
    "    match = regex_www.search(text)\n",
    "    if match:\n",
    "        return regex_www.sub(' ', text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_from_hashtag(text):\n",
    "    match = regex_hashtag.search(text)\n",
    "    if match:\n",
    "        return regex_hashtag.sub(' ', text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_port(res_url):\n",
    "    res_len = len(res_url)\n",
    "    for d in range(1, 7 if res_len > 5 else res_len+1):\n",
    "        if res_url[-d] == ':':\n",
    "            return res_url[:-d]\n",
    "    else:\n",
    "        return res_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# h or w\n",
    "# if h then stop on third / or on the end of the string (if no more /) https://test.com   www.test.com/\n",
    "# if w then stop on first / or on the end of the string (if no more /)\n",
    "def strip_urls(url):\n",
    "    cnt = 0\n",
    "    if len(url) == 0: return url\n",
    "    first = url[0]\n",
    "    \n",
    "    for i, c in enumerate(url):\n",
    "        if c == '/':\n",
    "            cnt += 1\n",
    "            if (first == 'h' and cnt == 3) or (first == 'w' and cnt == 1):\n",
    "                return strip_port(url[:i])\n",
    "    else:\n",
    "        return strip_port(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Clean text according to http://redmine-ots.co.spb.ru/issues/7415\n",
    "'''\n",
    "def clean_text(text):\n",
    "    return remove_long_words(\n",
    "                                regex_white_space.sub(' ', \n",
    "                                     clean_alone_digits(\n",
    "                                        clean_remaining_non_relevant_symb(\n",
    "                                            separate_dot_capital(\n",
    "                                                clean_non_relevant_symb(\n",
    "                                                    clean_from_hashtag(\n",
    "                                                        clean_from_www(\n",
    "                                                            clean_html_char_num(\n",
    "                                                                clean_from_emails(text))))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Сокращение хвостов происходит по проценту от общей суммы слов (90-95%), это значит: \n",
    "суммируются частоты всех слов (=100%), список слов ранжируется, например, по убыванию, \n",
    "и 5-10% «хвост» низкочастотного распределения отрезается (это почти 100% шум: ошибки, описки, прочий хлам). \n",
    "При этом общий объем частотного словаря уменьшится более, чем в два раза.\n",
    "\n",
    "Пример:\n",
    "3000 (100%)- общая сумма слов\n",
    "1500 уникальных слов (строк) в частотном словаре\n",
    "300    (10%)  - число по проценту от общей суммы слов\n",
    "обрезается 300 последних строк с самой низкой частотой 1500 - 300 = 1200 строк \n",
    "'''\n",
    "def fr_dist_with_domain(text, ref, slice_percent):\n",
    "    words_list = text.lower().split()\n",
    "    domain = strip_urls(ref).lower()\n",
    "        \n",
    "    di = dict()\n",
    "    \n",
    "    for w in words_list:\n",
    "        di[w] = di.get(w, 0) + 1\n",
    "    \n",
    "    items = sorted(di.items(), key=itemgetter(1), reverse=True)\n",
    "            \n",
    "    cnt_all = len(words_list)\n",
    "    cnt_dist = len(items)\n",
    "    \n",
    "    cnt_perc = cnt_all * slice_percent // 100\n",
    "    \n",
    "    return [item + (domain,) for item in items[:cnt_dist-cnt_perc]] # sliced tail by slice_percent 1500-300=1200  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "wet_list also accepts compressed files *.warc.wet.gz\n",
    "Процент обрезания задавать параметрически, чтобы постом можно было подобрать оптимальный.\n",
    "'''\n",
    "def clean_tokenize_frqdis_wet_files(wet_list=None, slice_percent=10):\n",
    "    if not wet_list:\n",
    "        print('wet_list is not specified')\n",
    "        return \n",
    "    \n",
    "    wet_list = wet_list[-1:] # one (last 00639) in list (require all list)\n",
    "#     wet_list = wet_list[0:1]\n",
    "    \n",
    "    for wet_file in wet_list:\n",
    "        warc = warcat.model.WARC()\n",
    "        warc.load(wet_file)\n",
    "        \n",
    "        pth = os.path.join('./output', wet_file[3:])\n",
    "#         lg = os.path.join('./logs', wet_file[3:]) # logging - continue\n",
    "\n",
    "        os.makedirs(pth, exist_ok=True)\n",
    "#         os.makedirs(lg, exist_ok=True)\n",
    "        \n",
    "        print('File: ', wet_file, 'Records: ', len(warc.records), sep='\\t', end='\\n\\n') # to logs is better\n",
    "        \n",
    "        wet_fr_dist = []\n",
    "        \n",
    "        for i, record in enumerate(warc.records[0:]): # sliced here!\n",
    "            file_uri = record.header.fields.get('WARC-Target-URI')\n",
    "            print(record.header.fields.list(), 'Num: ', i, sep='\\t', end='\\n\\n')\n",
    "            \n",
    "            if record.warc_type != 'warcinfo':\n",
    "                with record.content_block.get_file() as f:\n",
    "                    text = bytes.decode(f.read())\n",
    "#                     file_name_urn = record.header.fields.get('WARC-Record-ID').split(':')[-1][:-1] + '.txt'\n",
    "                    \n",
    "                    # а и по ним строить частотное распределение\n",
    "                    emails = ' '.join(regex_email.findall(text))\n",
    "                    sites = ' '.join(map(strip_urls, regex_www.findall(text)))\n",
    "                    hash_tags = ' '.join(regex_hashtag.findall(text))\n",
    "                    \n",
    "                    cleaned_text = clean_text(text) + '  ' + emails + '  ' + sites + '  ' + hash_tags\n",
    "                    fr_dist = fr_dist_with_domain(cleaned_text, file_uri, slice_percent)\n",
    "                    wet_fr_dist += fr_dist\n",
    "                    \n",
    "#                     with open(os.path.join(pth, file_name_urn), 'w') as f_to_fs:\n",
    "#                         f_to_fs.write(cleaned_text)\n",
    "                        \n",
    "#                     print('\\nDirty: \\n\\n', text, end='\\n\\n')\n",
    "#                     print('\\nFrDist: \\n\\n', fr_dist, '\\n', end='\\n\\n')\n",
    "#                     print('\\nCleaned text: \\n\\n', cleaned_text, end='\\n\\n')\n",
    "                    \n",
    "        else: # WET file end loop -- save to csv\n",
    "            file_name_wet_csv = wet_file[3:] + '.csv'\n",
    "            with open(os.path.join(pth, file_name_wet_csv), 'w', newline='') as csv_f:\n",
    "                writer = csv.writer(csv_f, delimiter='\\t')\n",
    "                writer.writerows(wet_fr_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('slice_percent', \n",
    "                        help='Slice percent. Used to cut off the trash tail of the frequency distribution.',\n",
    "                        type=int)\n",
    "    \n",
    "    prc = 0\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    prc = args.slice_percent\n",
    "    \n",
    "    clean_tokenize_frqdis_wet_files(glob.glob(\"../*.warc.wet*\"), prc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scr]",
   "language": "python",
   "name": "conda-env-scr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
